# -*- coding: utf-8 -*-
"""MRI_image_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fep8fAODoa4hVeXrVX2WwwMiV2g-3kWg
"""



from google.colab import files
uploaded = files.upload()

import zipfile

with zipfile.ZipFile('/content/archive.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/dataset')

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Convolution2D, Dropout, Dense, MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import Flatten
import os

# Verificar qu√© se extrajo
print("Contenido extra√≠do en /content/dataset:")
print(os.listdir('/content/dataset'))

# Verificar si hay subdirectorios
for item in os.listdir('/content/dataset'):
    item_path = os.path.join('/content/dataset', item)
    if os.path.isdir(item_path):
        print(f"\nContenido de {item}:")
        print(os.listdir(item_path))

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Convolution2D, Dropout, Dense, MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import Flatten
import os

# Importaciones adicionales necesarias
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Configurar par√°metros
IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 32

# Funci√≥n para cargar y preprocesar im√°genes
def load_and_preprocess_data(dataset_path):
    images = []
    labels = []

    # Buscar carpetas de clases (yes/no o tumor/no_tumor)
    class_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]
    print(f"Clases encontradas: {class_folders}")

    for class_idx, class_name in enumerate(class_folders):
        class_path = os.path.join(dataset_path, class_name)
        print(f"Procesando clase: {class_name}")

        for img_file in os.listdir(class_path):
            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                img_path = os.path.join(class_path, img_file)

                # Cargar y redimensionar imagen
                img = cv2.imread(img_path)
                if img is not None:
                    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir BGR a RGB
                    images.append(img)
                    labels.append(class_idx)

    return np.array(images), np.array(labels)

# Cargar datos
print("Cargando im√°genes...")
X, y = load_and_preprocess_data('/content/dataset')

print(f"Total de im√°genes: {len(X)}")
print(f"Forma de las im√°genes: {X.shape}")
print(f"Distribuci√≥n de clases: {np.bincount(y)}")

# Normalizar las im√°genes (valores entre 0 y 1)
X = X.astype('float32') / 255.0

# Dividir en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

print(f"Entrenamiento: {X_train.shape[0]} im√°genes")
print(f"Validaci√≥n: {X_val.shape[0]} im√°genes")
print(f"Prueba: {X_test.shape[0]} im√°genes")

# Crear el modelo CNN
model = Sequential([
    Convolution2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    Convolution2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    Convolution2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    Convolution2D(256, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Clasificaci√≥n binaria
])

# Compilar el modelo
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Mostrar resumen del modelo
model.summary()

# Configurar callbacks
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=5,
    min_lr=0.0001
)

print("Iniciando entrenamiento...")
history = model.fit(
    X_train, y_train,
    batch_size=BATCH_SIZE,
    epochs=50,
    validation_data=(X_val, y_val),
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# Evaluar el modelo
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Precisi√≥n en prueba: {test_accuracy:.4f}")

# Graficar resultados del entrenamiento
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validaci√≥n')
plt.title('Precisi√≥n del Modelo')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida del Modelo')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()

plt.tight_layout()
plt.show()

# Guardar el modelo entrenado
model.save('modelo_tumor_cerebral.h5')
print("Modelo guardado como 'modelo_tumor_cerebral.h5'")

# Funci√≥n para hacer m√∫ltiples predicciones
def analizar_multiples_imagenes():
    """
    Funci√≥n para analizar m√∫ltiples im√°genes de una vez
    """
    from google.colab import files
    print("üì§ Selecciona m√∫ltiples im√°genes MRI para analizar:")
    uploaded = files.upload()

    if not uploaded:
        print("‚ùå No se subieron im√°genes")
        return

    resultados = []

    for nombre_archivo in uploaded.keys():
        print(f"\nüîç Analizando: {nombre_archivo}")
        resultado = predecir_tumor(model, nombre_archivo)
        if resultado:
            resultados.append({
                'archivo': nombre_archivo,
                **resultado
            })

    # Resumen de resultados
    print("\nüìã RESUMEN DE AN√ÅLISIS:")
    print("-" * 50)
    for i, res in enumerate(resultados, 1):
        print(f"{i}. {res['archivo']}")
        print(f"   {res['resultado']} (Confianza: {res['confianza']:.1f}%)")

    return resultados

# Funci√≥n para probar con im√°genes del dataset de prueba
def probar_con_dataset_prueba(num_muestras=5):
    """
    Funci√≥n para probar el modelo con im√°genes aleatorias del conjunto de prueba
    """
    indices = np.random.choice(len(X_test), num_muestras, replace=False)

    plt.figure(figsize=(15, 3 * num_muestras))

    for i, idx in enumerate(indices):
        img = X_test[idx]
        etiqueta_real = y_test[idx]

        # Hacer predicci√≥n
        img_pred = np.expand_dims(img, axis=0)
        prediccion = model.predict(img_pred, verbose=0)
        probabilidad = prediccion[0][0]

        # Interpretar resultados
        etiqueta_pred = 1 if probabilidad > 0.5 else 0
        resultado_real = "Tumor" if etiqueta_real == 1 else "No Tumor"
        resultado_pred = "Tumor" if etiqueta_pred == 1 else "No Tumor"

        # Color del borde seg√∫n acierto/error
        color = 'green' if etiqueta_real == etiqueta_pred else 'red'

        plt.subplot(num_muestras, 1, i+1)
        plt.imshow(img)
        plt.title(f'Real: {resultado_real} | Predicci√≥n: {resultado_pred} (Confianza: {max(probabilidad, 1-probabilidad)*100:.1f}%)')
        plt.axis('off')

        # Agregar borde de color
        ax = plt.gca()
        for spine in ax.spines.values():
            spine.set_edgecolor(color)
            spine.set_linewidth(3)

    plt.tight_layout()
    plt.show()

print("\nüéâ ¬°MODELO ENTRENADO Y LISTO!")
print("\nüìù Funciones disponibles:")
print("1. predecir_tumor(model) - Sube una imagen y obt√©n predicci√≥n")
print("2. analizar_multiples_imagenes() - Analiza varias im√°genes a la vez")
print("3. probar_con_dataset_prueba() - Prueba con im√°genes del dataset")
print("\nüí° Ejemplo de uso:")
print("   resultado = predecir_tumor(model)")
print("   probar_con_dataset_prueba(3)")

# Para analizar una sola imagen
resultado = predecir_tumor(model)

# Para analizar m√∫ltiples im√°genes
resultados = analizar_multiples_imagenes()

# Para probar con 5 im√°genes del dataset
probar_con_dataset_prueba(5)

!git config --global user.email "keviniacs222@gmail.com"
!git config --global user.name "keviacs"

# Crear carpeta y copiar archivos
!mkdir brain-tumor-detection
!ls -la  # Ver qu√© archivos tienes disponibles

# Copiar archivos principales al proyecto
!cp modelo_tumor_cerebral.h5 brain-tumor-detection/
!cp *.py brain-tumor-detection/ 2>/dev/null || echo "No hay archivos .py en el directorio principal"

# Verificar qu√© archivos se copiaron
!ls -la brain-tumor-detection/

readme_content = '''# Brain Tumor Detection using CNN

## Overview
This project implements a Convolutional Neural Network (CNN) for detecting brain tumors in medical images.

## Features
- Image preprocessing and augmentation
- CNN model architecture
- Training and validation
- Model evaluation and metrics

## Requirements
- Python 3.x
- TensorFlow/Keras
- NumPy
- OpenCV
- Matplotlib

## Usage
1. Prepare your dataset
2. Run the training script
3. Evaluate the model
4. Make predictions on new images

## Results
- Accuracy: XX%
- Precision: XX%
- Recall: XX%
'''

# Commented out IPython magic to ensure Python compatibility.
# 1. Instalar y configurar Git
!git config --global user.email "tu_email@gmail.com"
!git config --global user.name "Tu Nombre"

# 2. Clonar un repositorio vac√≠o que hayas creado en GitHub
!git clone https://github.com/TU_USUARIO/brain-tumor-detection-cnn.git

# 3. Cambiar al directorio
# %cd brain-tumor-detection-cnn

# 4. Crear tus archivos (README, c√≥digo, etc.)
readme_content = '''# Brain Tumor Detection using CNN

## Overview
This project implements a Convolutional Neural Network for detecting brain tumors in medical images using Google Colab.

## Dataset
- Medical images of brain scans
- Binary classification: Tumor vs No Tumor

## Model Architecture
- Convolutional Neural Network
- Built with TensorFlow/Keras

## Results
- Training accuracy: XX%
- Validation accuracy: XX%

## Usage in Google Colab
1. Upload dataset to Colab
2. Run the training notebook
3. Evaluate results

## Files
- `brain_tumor_detection.ipynb`: Main training notebook
- `model.h5`: Trained model weights
- `README.md`: Project documentation
'''

# Guardar el README
with open('README.md', 'w') as f:
    f.write(readme_content)

# 5. Agregar archivos y hacer commit
!git add .
!git commit -m "Initial commit: Brain tumor detection project from Colab"

# 6. Subir a GitHub
!git push origin main

# REEMPLAZA CON TU TOKEN REAL
TOKEN = "your token here"
USERNAME = "keviacs"
REPO_NAME = "brain-tumor-detection-cnn"

# Configurar Git
!git config --global user.email "keviniacs222@gmail.com"
!git config --global user.name "keviacs"

# Clonar tu repositorio
!git clone https://{TOKEN}@github.com/{USERNAME}/{REPO_NAME}.git

# Entrar al directorio
import os
os.chdir(f'/content/{REPO_NAME}')

# Verificar que funcion√≥
!pwd
!ls -la

readme_content = '''# Brain Tumor Detection using CNN

This project uses a Convolutional Neural Network (CNN) to classify MRI brain images for tumor detection.

## Requirements
- Python 3.x
- TensorFlow or Keras
- NumPy
- Matplotlib

## Usage
1. Prepare your dataset with MRI images.
2. Train the model with `python train.py`.
3. Evaluate or predict with new images.

## License
MIT License.
'''
